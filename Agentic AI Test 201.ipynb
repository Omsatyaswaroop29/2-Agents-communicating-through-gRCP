{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhI5H43-I-v_",
        "outputId": "29c822bc-9c65-484b-8427-b4a3b94bc72b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "grpcio-status 1.71.2 requires grpcio>=1.71.2, but you have grpcio 1.70.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install autogen-ext[grpc] gradio -q\n",
        "\n",
        "# Additional installations for Colab environment\n",
        "!pip install nest-asyncio -q  # Needed for async in Jupyter\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6juq2TQOKyD-",
        "outputId": "38511317-c514-4f84-926a-9cec209420f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: autogen-core in /usr/local/lib/python3.11/dist-packages (0.6.4)\n",
            "Requirement already satisfied: autogen-agentchat in /usr/local/lib/python3.11/dist-packages (0.6.4)\n",
            "Requirement already satisfied: autogen-ext[semantic-kernel-google] in /usr/local/lib/python3.11/dist-packages (0.6.4)\n",
            "Requirement already satisfied: jsonref~=1.1.0 in /usr/local/lib/python3.11/dist-packages (from autogen-core) (1.1.0)\n",
            "Requirement already satisfied: opentelemetry-api>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from autogen-core) (1.35.0)\n",
            "Requirement already satisfied: pillow>=11.0.0 in /usr/local/lib/python3.11/dist-packages (from autogen-core) (11.3.0)\n",
            "Requirement already satisfied: protobuf~=5.29.3 in /usr/local/lib/python3.11/dist-packages (from autogen-core) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.10.0 in /usr/local/lib/python3.11/dist-packages (from autogen-core) (2.11.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from autogen-core) (4.14.1)\n",
            "Requirement already satisfied: semantic-kernel>=1.17.1 in /usr/local/lib/python3.11/dist-packages (from semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (1.35.0)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.34.1->autogen-core) (8.7.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.10.0->autogen-core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.10.0->autogen-core) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.10.0->autogen-core) (0.4.1)\n",
            "Requirement already satisfied: azure-ai-projects>=1.0.0b11 in /usr/local/lib/python3.11/dist-packages (from semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (1.0.0b12)\n",
            "Requirement already satisfied: azure-ai-agents>=1.1.0b1 in /usr/local/lib/python3.11/dist-packages (from semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (1.1.0b4)\n",
            "Requirement already satisfied: aiohttp~=3.8 in /usr/local/lib/python3.11/dist-packages (from semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (3.12.14)\n",
            "Requirement already satisfied: cloudevents~=1.0 in /usr/local/lib/python3.11/dist-packages (from semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (1.12.0)\n",
            "Requirement already satisfied: pydantic-settings~=2.0 in /usr/local/lib/python3.11/dist-packages (from semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (2.10.1)\n",
            "Requirement already satisfied: defusedxml~=0.7 in /usr/local/lib/python3.11/dist-packages (from semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (0.7.1)\n",
            "Requirement already satisfied: azure-identity>=1.13 in /usr/local/lib/python3.11/dist-packages (from semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (1.23.1)\n",
            "Requirement already satisfied: numpy>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (2.0.2)\n",
            "Requirement already satisfied: openai>=1.67 in /usr/local/lib/python3.11/dist-packages (from semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (1.97.1)\n",
            "Requirement already satisfied: openapi_core<0.20,>=0.18 in /usr/local/lib/python3.11/dist-packages (from semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (0.19.5)\n",
            "Requirement already satisfied: websockets<16,>=13 in /usr/local/lib/python3.11/dist-packages (from semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (15.0.1)\n",
            "Requirement already satisfied: aiortc>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (1.13.0)\n",
            "Requirement already satisfied: opentelemetry-sdk~=1.24 in /usr/local/lib/python3.11/dist-packages (from semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (1.35.0)\n",
            "Requirement already satisfied: prance<25.4.9,>=23.6.21 in /usr/local/lib/python3.11/dist-packages (from semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (25.4.8.0)\n",
            "Requirement already satisfied: pybars4~=0.9 in /usr/local/lib/python3.11/dist-packages (from semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (0.9.13)\n",
            "Requirement already satisfied: jinja2~=3.1 in /usr/local/lib/python3.11/dist-packages (from semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (3.1.6)\n",
            "Requirement already satisfied: nest-asyncio~=1.6 in /usr/local/lib/python3.11/dist-packages (from semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (1.6.0)\n",
            "Requirement already satisfied: scipy>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (1.16.0)\n",
            "Requirement already satisfied: google-cloud-aiplatform==1.97.0 in /usr/local/lib/python3.11/dist-packages (from semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (1.97.0)\n",
            "Requirement already satisfied: google-generativeai~=0.8 in /usr/local/lib/python3.11/dist-packages (from semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (0.8.5)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform==1.97.0->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (2.25.1)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform==1.97.0->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform==1.97.0->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (1.26.1)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform==1.97.0->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (25.0)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0,>=1.32.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform==1.97.0->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (2.19.0)\n",
            "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform==1.97.0->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (3.35.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0,>=1.3.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform==1.97.0->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (1.14.2)\n",
            "Requirement already satisfied: shapely<3.0.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform==1.97.0->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (2.1.1)\n",
            "Requirement already satisfied: google-genai<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform==1.97.0->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (1.27.0)\n",
            "Requirement already satisfied: docstring_parser<1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform==1.97.0->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (0.17.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp~=3.8->semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp~=3.8->semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp~=3.8->semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp~=3.8->semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp~=3.8->semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp~=3.8->semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp~=3.8->semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (1.20.1)\n",
            "Requirement already satisfied: aioice<1.0.0,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from aiortc>=1.9.0->semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (0.10.1)\n",
            "Requirement already satisfied: av<15.0.0,>=14.0.0 in /usr/local/lib/python3.11/dist-packages (from aiortc>=1.9.0->semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (14.4.0)\n",
            "Requirement already satisfied: cffi>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from aiortc>=1.9.0->semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (1.17.1)\n",
            "Requirement already satisfied: cryptography>=44.0.0 in /usr/local/lib/python3.11/dist-packages (from aiortc>=1.9.0->semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (45.0.5)\n",
            "Requirement already satisfied: google-crc32c>=1.1 in /usr/local/lib/python3.11/dist-packages (from aiortc>=1.9.0->semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (1.7.1)\n",
            "Requirement already satisfied: pyee>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from aiortc>=1.9.0->semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (13.0.0)\n",
            "Requirement already satisfied: pylibsrtp>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from aiortc>=1.9.0->semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (0.12.0)\n",
            "Requirement already satisfied: pyopenssl>=25.0.0 in /usr/local/lib/python3.11/dist-packages (from aiortc>=1.9.0->semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (25.1.0)\n",
            "Requirement already satisfied: isodate>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from azure-ai-agents>=1.1.0b1->semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (0.7.2)\n",
            "Requirement already satisfied: azure-core>=1.30.0 in /usr/local/lib/python3.11/dist-packages (from azure-ai-agents>=1.1.0b1->semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (1.35.0)\n",
            "Requirement already satisfied: azure-storage-blob>=12.15.0 in /usr/local/lib/python3.11/dist-packages (from azure-ai-projects>=1.0.0b11->semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (12.26.0)\n",
            "Requirement already satisfied: msal>=1.30.0 in /usr/local/lib/python3.11/dist-packages (from azure-identity>=1.13->semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (1.33.0)\n",
            "Requirement already satisfied: msal-extensions>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from azure-identity>=1.13->semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (1.3.1)\n",
            "Requirement already satisfied: deprecation<3.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from cloudevents~=1.0->semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (2.1.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai~=0.8->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (0.6.15)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai~=0.8->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (2.177.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai~=0.8->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (4.67.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.34.1->autogen-core) (3.23.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2~=3.1->semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (3.0.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.67->semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.67->semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.67->semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.67->semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.67->semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (1.3.1)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from openapi_core<0.20,>=0.18->semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (4.25.0)\n",
            "Requirement already satisfied: jsonschema-path<0.4.0,>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from openapi_core<0.20,>=0.18->semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (0.3.4)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openapi_core<0.20,>=0.18->semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (10.7.0)\n",
            "Requirement already satisfied: openapi-schema-validator<0.7.0,>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from openapi_core<0.20,>=0.18->semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (0.6.3)\n",
            "Requirement already satisfied: openapi-spec-validator<0.8.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from openapi_core<0.20,>=0.18->semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (0.7.2)\n",
            "Requirement already satisfied: parse in /usr/local/lib/python3.11/dist-packages (from openapi_core<0.20,>=0.18->semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (1.20.2)\n",
            "Requirement already satisfied: werkzeug<3.1.2 in /usr/local/lib/python3.11/dist-packages (from openapi_core<0.20,>=0.18->semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (3.1.1)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.56b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk~=1.24->semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (0.56b0)\n",
            "Requirement already satisfied: chardet>=5.2 in /usr/local/lib/python3.11/dist-packages (from prance<25.4.9,>=23.6.21->semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (5.2.0)\n",
            "Requirement already satisfied: ruamel.yaml>=0.18.10 in /usr/local/lib/python3.11/dist-packages (from prance<25.4.9,>=23.6.21->semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (0.18.14)\n",
            "Requirement already satisfied: requests>=2.32.3 in /usr/local/lib/python3.11/dist-packages (from prance<25.4.9,>=23.6.21->semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (2.32.3)\n",
            "Requirement already satisfied: PyMeta3>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from pybars4~=0.9->semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (0.5.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings~=2.0->semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (1.1.1)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from aioice<1.0.0,>=0.10.1->aiortc>=1.9.0->semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (2.7.0)\n",
            "Requirement already satisfied: ifaddr>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aioice<1.0.0,>=0.10.1->aiortc>=1.9.0->semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (0.2.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai>=1.67->semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (3.10)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from azure-core>=1.30.0->azure-ai-agents>=1.1.0b1->semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (1.17.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.0->aiortc>=1.9.0->semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (2.22)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform==1.97.0->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (1.70.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform==1.97.0->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (1.70.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform==1.97.0->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform==1.97.0->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform==1.97.0->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform==1.97.0->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (4.9.1)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform==1.97.0->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (2.4.3)\n",
            "Requirement already satisfied: google-resumable-media<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform==1.97.0->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (2.7.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0->google-cloud-aiplatform==1.97.0->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (2.9.0.post0)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-resource-manager<3.0.0,>=1.3.3->google-cloud-aiplatform==1.97.0->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (0.14.2)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform==1.97.0->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (8.5.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai>=1.67->semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai>=1.67->semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.67->semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (0.16.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (0.26.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema-path<0.4.0,>=0.3.1->openapi_core<0.20,>=0.18->semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (6.0.2)\n",
            "Requirement already satisfied: pathable<0.5.0,>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema-path<0.4.0,>=0.3.1->openapi_core<0.20,>=0.18->semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (0.4.4)\n",
            "Requirement already satisfied: PyJWT<3,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure-identity>=1.13->semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (2.10.1)\n",
            "Requirement already satisfied: rfc3339-validator in /usr/local/lib/python3.11/dist-packages (from openapi-schema-validator<0.7.0,>=0.6.0->openapi_core<0.20,>=0.18->semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (0.1.4)\n",
            "Requirement already satisfied: lazy-object-proxy<2.0.0,>=1.7.1 in /usr/local/lib/python3.11/dist-packages (from openapi-spec-validator<0.8.0,>=0.7.1->openapi_core<0.20,>=0.18->semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (1.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.3->prance<25.4.9,>=23.6.21->semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.3->prance<25.4.9,>=23.6.21->semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (2.5.0)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /usr/local/lib/python3.11/dist-packages (from ruamel.yaml>=0.18.10->prance<25.4.9,>=23.6.21->semantic-kernel>=1.17.1->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (0.2.12)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai~=0.8->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai~=0.8->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai~=0.8->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (4.2.0)\n",
            "Collecting grpcio<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform==1.97.0->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google])\n",
            "  Using cached grpcio-1.74.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai~=0.8->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (3.2.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-cloud-aiplatform==1.97.0->semantic-kernel[google]>=1.17.1; extra == \"semantic-kernel-google\"->autogen-ext[semantic-kernel-google]) (0.6.1)\n",
            "Using cached grpcio-1.74.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n",
            "Installing collected packages: grpcio\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.70.0\n",
            "    Uninstalling grpcio-1.70.0:\n",
            "      Successfully uninstalled grpcio-1.70.0\n",
            "Successfully installed grpcio-1.74.0\n"
          ]
        }
      ],
      "source": [
        "!pip install autogen-core autogen-agentchat \"autogen-ext[semantic-kernel-google]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GForDlqsJMWv",
        "outputId": "dc941b90-38e9-4096-f7dc-1090d3be79c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… All packages installed successfully!\n"
          ]
        }
      ],
      "source": [
        "# %%\n",
        "# Import necessary libraries\n",
        "import asyncio\n",
        "import json\n",
        "import logging\n",
        "import sys\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Dict, Optional\n",
        "from datetime import datetime\n",
        "import gradio as gr\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "# AutoGen imports\n",
        "from autogen_core import (\n",
        "    DefaultTopicId,\n",
        "    MessageContext,\n",
        "    RoutedAgent,\n",
        "    default_subscription,\n",
        "    message_handler\n",
        ")\n",
        "from autogen_ext.runtimes.grpc import (\n",
        "    GrpcWorkerAgentRuntimeHost,\n",
        "    GrpcWorkerAgentRuntime\n",
        ")\n",
        "\n",
        "# Enable async in Jupyter/Colab\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "print(\"âœ… All packages installed successfully!\")\n",
        "\n",
        "\n",
        "# ## Agent Implementation with Proper Communication Setup\n",
        "\n",
        "from autogen_agentchat.messages import TextMessage\n",
        "from autogen_core import TopicId, TypeSubscription\n",
        "import json\n",
        "\n",
        "# Define a shared topic for communication\n",
        "TRANSLATION_TOPIC = TopicId(\"translation_topic\", \"translation_topic\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYmQzFUnJTl0",
        "outputId": "28e9cebe-d2fa-4f26-d691-1e5f6c5e74d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Message types defined!\n",
            "âœ… Message types defined!\n"
          ]
        }
      ],
      "source": [
        "# ## 2. Core Components <a id=\"components\"></a>\n",
        "#\n",
        "# Let's define the core message types that our agents will use to communicate.\n",
        "\n",
        "# %%\n",
        "# Define message types for agent communication\n",
        "from dataclasses import dataclass\n",
        "from typing import Dict\n",
        "import json\n",
        "\n",
        "# @dataclass\n",
        "# class QueryTranslationRequest:\n",
        "#     \"\"\"\n",
        "#     Message sent by RequestAgent to request SQL translation\n",
        "#     \"\"\"\n",
        "#     request_id: str                     # Unique identifier for tracking\n",
        "#     natural_language_query: str         # The query to translate\n",
        "#     database_schema_json: str          # Schema information as JSON string\n",
        "#     sender: str                        # Agent that sent the request\n",
        "#     timestamp: str                     # When the request was sent\n",
        "\n",
        "# @dataclass\n",
        "# class QueryTranslationResponse:\n",
        "#     \"\"\"\n",
        "#     Message sent by TranslatorAgent with SQL translation result\n",
        "#     \"\"\"\n",
        "#     request_id: str      # Matches the request ID\n",
        "#     sql_query: str       # Generated SQL query\n",
        "#     confidence: float    # Confidence score (0-1)\n",
        "#     explanation: str     # Explanation of the translation\n",
        "#     responder: str       # Agent that created the response\n",
        "#     timestamp: str       # When the response was sent\n",
        "\n",
        "print(\"âœ… Message types defined!\")\n",
        "\n",
        "# Message type definitions as string constants\n",
        "QUERY_TRANSLATION_REQUEST = \"QueryTranslationRequest\"\n",
        "QUERY_TRANSLATION_RESPONSE = \"QueryTranslationResponse\"\n",
        "\n",
        "print(\"âœ… Message types defined!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rzNkrMeJZzv",
        "outputId": "d67bf0cc-0712-40c3-f222-68de8d40bbda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TEST] System: Logging system initialized\n",
            "\n",
            "Current log entries: 1\n"
          ]
        }
      ],
      "source": [
        "# ## 3. Communication Log System <a id=\"log\"></a>\n",
        "#\n",
        "# We'll implement a logging system to track all agent communications for visualization.\n",
        "\n",
        "# %%\n",
        "# Global communication log to track all messages\n",
        "communication_log = []\n",
        "\n",
        "def log_communication(entry_type: str, agent: str, data: dict):\n",
        "    \"\"\"\n",
        "    Add an entry to the communication log\n",
        "    \"\"\"\n",
        "    entry = {\n",
        "        \"type\": entry_type,\n",
        "        \"agent\": agent,\n",
        "        \"data\": data,\n",
        "        \"timestamp\": datetime.now().isoformat()\n",
        "    }\n",
        "    communication_log.append(entry)\n",
        "\n",
        "    # Print to console for debugging\n",
        "    print(f\"[{entry_type.upper()}] {agent}: {data.get('status', data.get('query', 'Processing...'))}\")\n",
        "\n",
        "def clear_communication_log():\n",
        "    \"\"\"Clear all entries from the communication log\"\"\"\n",
        "    global communication_log\n",
        "    communication_log = []\n",
        "    print(\"âœ… Communication log cleared\")\n",
        "\n",
        "# Test the logging system\n",
        "log_communication(\"test\", \"System\", {\"status\": \"Logging system initialized\"})\n",
        "print(f\"\\nCurrent log entries: {len(communication_log)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "gRtkxvuXjNJ3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hHrc4Di9jM0Y"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4kh6pj1Jb6n",
        "outputId": "24824fcd-fd8e-4d9a-886b-0ac393ffe4c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… RequestAgent implemented!\n"
          ]
        }
      ],
      "source": [
        "# ## Simplified Cross-Runtime Agent System\n",
        "# Both agents register on both runtimes to enable communication\n",
        "\n",
        "from autogen_agentchat.messages import TextMessage\n",
        "import json\n",
        "import os\n",
        "\n",
        "# ### 4.1 Request Agent\n",
        "@default_subscription\n",
        "class RequestAgent(RoutedAgent):\n",
        "    \"\"\"\n",
        "    Agent that sends natural language queries for SQL translation\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, name: str) -> None:\n",
        "        super().__init__(f\"RequestAgent-{name}\")\n",
        "        self._name = name\n",
        "        self._pending_requests = {}  # Track requests awaiting responses\n",
        "\n",
        "    async def send_translation_request(self, query: str, schema: Dict) -> None:\n",
        "        \"\"\"\n",
        "        Send a query translation request to the network\n",
        "        \"\"\"\n",
        "        # Generate unique request ID\n",
        "        request_id = f\"req_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}\"\n",
        "\n",
        "        # Create request data as JSON\n",
        "        request_data = {\n",
        "            \"type\": \"QueryTranslationRequest\",\n",
        "            \"request_id\": request_id,\n",
        "            \"natural_language_query\": query,\n",
        "            \"database_schema\": schema,\n",
        "            \"sender\": self._name,\n",
        "            \"timestamp\": datetime.now().isoformat()\n",
        "        }\n",
        "\n",
        "        # Create TextMessage with JSON content\n",
        "        message = TextMessage(\n",
        "            content=json.dumps(request_data),\n",
        "            source=self._name\n",
        "        )\n",
        "\n",
        "        # Log the request\n",
        "        log_communication(\"request\", self._name, {\n",
        "            \"request_id\": request_id,\n",
        "            \"query\": query,\n",
        "            \"schema\": schema\n",
        "        })\n",
        "        print(f\"\\nðŸ“¤ RequestAgent sending message\")\n",
        "\n",
        "        # Store pending request\n",
        "        self._pending_requests[request_id] = request_data\n",
        "\n",
        "        # Send message using default topic\n",
        "        await self.publish_message(message, DefaultTopicId())\n",
        "\n",
        "    @message_handler\n",
        "    async def handle_message(self, message: TextMessage, ctx: MessageContext) -> None:\n",
        "        \"\"\"\n",
        "        Handle incoming messages\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Parse the message content\n",
        "            data = json.loads(message.content)\n",
        "\n",
        "            # Only process responses, not requests\n",
        "            if data.get(\"type\") == \"QueryTranslationResponse\":\n",
        "                print(f\"\\nðŸ“¥ RequestAgent received response from: {message.source}\")\n",
        "                print(f\"   Message type: {data.get('type')}\")\n",
        "\n",
        "                request_id = data.get(\"request_id\")\n",
        "                if request_id in self._pending_requests:\n",
        "                    # Log the response\n",
        "                    log_communication(\"response\", self._name, {\n",
        "                        \"request_id\": request_id,\n",
        "                        \"sql_query\": data.get(\"sql_query\"),\n",
        "                        \"confidence\": data.get(\"confidence\"),\n",
        "                        \"explanation\": data.get(\"explanation\")\n",
        "                    })\n",
        "\n",
        "                    # Remove from pending\n",
        "                    del self._pending_requests[request_id]\n",
        "                    print(f\"   âœ… Processed response for request: {request_id}\")\n",
        "        except json.JSONDecodeError:\n",
        "            pass  # Ignore non-JSON messages\n",
        "        except Exception as e:\n",
        "            print(f\"   Error handling message: {e}\")\n",
        "\n",
        "print(\"âœ… RequestAgent implemented!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "gBNulBeYJf51"
      },
      "outputs": [],
      "source": [
        "from autogen_agentchat.agents import AssistantAgent\n",
        "from autogen_agentchat.messages import TextMessage\n",
        "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
        "from autogen_core.models import ModelFamily\n",
        "\n",
        "from autogen_core import MessageContext, RoutedAgent, message_handler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "fuHt7GyYSB2P"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWMD8S2DK_VY",
        "outputId": "40d93800-e043-4698-b2a9-a72e03208b7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Updated TranslatorAgent with better API key handling!\n"
          ]
        }
      ],
      "source": [
        "# ### 4.2 Translator Agent\n",
        "# ## Updated TranslatorAgent with Better API Key Handling\n",
        "# %%\n",
        "@default_subscription\n",
        "class TranslatorAgent(RoutedAgent):\n",
        "    \"\"\"\n",
        "    Agent that translates natural language queries to SQL\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, name: str) -> None:\n",
        "        super().__init__(f\"TranslatorAgent-{name}\")\n",
        "        self._name = name\n",
        "\n",
        "        self.model_client = OpenAIChatCompletionClient(\n",
        "            model=\"gemini-2.0-flash\",\n",
        "            api_key=userdata.get(\"GOOGLE_API_KEY\"),\n",
        "            base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
        "            model_info={\n",
        "                \"family\": ModelFamily.GEMINI_2_0_FLASH,\n",
        "                \"function_calling\": True,\n",
        "                \"json_output\": True,\n",
        "                \"vision\": False,\n",
        "                \"structured_output\": True,\n",
        "            }\n",
        "        )\n",
        "        print(f\"   âœ… Gemini LLM client initialized for {name}\")\n",
        "        # Create a prompt for the LLM\n",
        "        system_prompt = \"\"\"You are a SQL expert. Generate SQL queries from natural language descriptions.\n",
        "\n",
        "        Return your response as a JSON object with the following structure:\n",
        "        {\n",
        "            \"sql_query\": \"The SQL query\",\n",
        "            \"confidence\": 0.0 to 1.0 (how confident you are in the query),\n",
        "            \"explanation\": \"Brief explanation of what the query does\"\n",
        "        }\n",
        "\n",
        "        Important rules:\n",
        "        - Generate valid SQL syntax\n",
        "        - Use proper JOIN syntax when needed\n",
        "        - Include appropriate WHERE, GROUP BY, ORDER BY clauses as needed\n",
        "        - For ambiguous requests, make reasonable assumptions\n",
        "        - If you cannot generate a valid query, set confidence below 0.5\n",
        "        \"\"\"\n",
        "        self._delegate = AssistantAgent(name, model_client=self.model_client, system_message=system_prompt)\n",
        "\n",
        "    async def _generate_sql_with_llm(self, query: str, schema: Dict[str, List[Dict[str, str]]], ctx: MessageContext) -> tuple[str, float, str]:\n",
        "        \"\"\"\n",
        "        Generate SQL from natural language using Gemini LLM\n",
        "        \"\"\"\n",
        "\n",
        "        # Format schema information for the prompt\n",
        "        schema_info = \"Database Schema:\\n\"\n",
        "        for table_name, columns in schema.items():\n",
        "            schema_info += f\"\\nTable: {table_name}\\n\"\n",
        "            schema_info += \"Columns:\\n\"\n",
        "            for col in columns:\n",
        "                schema_info += f\"  - {col['name']}: {col['type']}\\n\"\n",
        "\n",
        "        user_prompt = f\"\"\"{schema_info}\n",
        "\n",
        "Natural Language Query: {query}\n",
        "\n",
        "Generate the SQL query for this request.\"\"\"\n",
        "\n",
        "        try:\n",
        "            print(f\"   ðŸ¤– Calling Gemini LLM...\")\n",
        "            # Make the API call\n",
        "            response = await self._delegate.on_messages(\n",
        "                [TextMessage(content=user_prompt, source=\"user\")],\n",
        "                ctx.cancellation_token\n",
        "            )\n",
        "\n",
        "            print(response.chat_message)\n",
        "            # Parse the response\n",
        "            content = response.chat_message.content.replace(\"```json\", \"\").replace(\"```\", \"\")\n",
        "            result = json.loads(content)\n",
        "            print(result)\n",
        "\n",
        "            sql_query = result.get(\"sql_query\", \"-- Unable to generate SQL\")\n",
        "            confidence = float(result.get(\"confidence\", 0.0))\n",
        "            explanation = result.get(\"explanation\", \"No explanation provided\")\n",
        "\n",
        "            # Validate confidence is between 0 and 1\n",
        "            confidence = max(0.0, min(1.0, confidence))\n",
        "\n",
        "            print(f\"   âœ… LLM generated SQL successfully\")\n",
        "\n",
        "        except Exception as e:\n",
        "            # Handle API errors gracefully\n",
        "            print(f\"   âŒ LLM error: {str(e)}\")\n",
        "            sql_query = \"-- Error generating SQL query\"\n",
        "            confidence = 0.0\n",
        "            explanation = f\"Error occurred during SQL generation: {str(e)}\"\n",
        "\n",
        "            # Log the error for debugging\n",
        "            log_communication(\"error\", self._name, {\n",
        "                \"error\": str(e),\n",
        "                \"query\": query\n",
        "            })\n",
        "\n",
        "        return sql_query, confidence, explanation\n",
        "\n",
        "    @message_handler\n",
        "    async def handle_message(self, message: TextMessage, ctx: MessageContext) -> None:\n",
        "        \"\"\"\n",
        "        Handle incoming messages\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Parse the message content\n",
        "            data = json.loads(message.content)\n",
        "\n",
        "            # Only process requests, not responses\n",
        "            if data.get(\"type\") == \"QueryTranslationRequest\":\n",
        "                print(f\"\\nðŸ“¥ TranslatorAgent received request from: {message.source}\")\n",
        "                print(f\"   Message type: {data.get('type')}\")\n",
        "\n",
        "                request_id = data.get(\"request_id\")\n",
        "                print(f\"   Processing translation request: {request_id}\")\n",
        "\n",
        "                # Log processing start\n",
        "                log_communication(\"processing\", self._name, {\n",
        "                    \"request_id\": request_id,\n",
        "                    \"status\": \"Translating query...\"\n",
        "                })\n",
        "\n",
        "                # Generate SQL using the LLM\n",
        "                sql_query, confidence, explanation = await self._generate_sql_with_llm(\n",
        "                    data.get(\"natural_language_query\"),\n",
        "                    data.get(\"database_schema\"),\n",
        "                    ctx\n",
        "                )\n",
        "\n",
        "                # Create response data\n",
        "                response_data = {\n",
        "                    \"type\": \"QueryTranslationResponse\",\n",
        "                    \"request_id\": request_id,\n",
        "                    \"sql_query\": sql_query,\n",
        "                    \"confidence\": confidence,\n",
        "                    \"explanation\": explanation,\n",
        "                    \"responder\": self._name,\n",
        "                    \"timestamp\": datetime.now().isoformat()\n",
        "                }\n",
        "\n",
        "                # Create TextMessage with JSON content\n",
        "                response = TextMessage(\n",
        "                    content=json.dumps(response_data),\n",
        "                    source=self._name\n",
        "                )\n",
        "\n",
        "                print(f\"   ðŸ“¤ Sending response back\")\n",
        "\n",
        "                # Send response\n",
        "                await self.publish_message(response, DefaultTopicId())\n",
        "\n",
        "        except json.JSONDecodeError:\n",
        "            pass  # Ignore non-JSON messages\n",
        "        except Exception as e:\n",
        "            print(f\"   Error handling message: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "print(\"âœ… Updated TranslatorAgent with better API key handling!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DW8welSAmsLI",
        "outputId": "05ea0c9d-bc77-4ca2-df13-9486c1a90d45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… MessageRelayAgent implemented!\n"
          ]
        }
      ],
      "source": [
        "# ### 4.3 Message Relay Agent (DEFINE THIS BEFORE USING IT)\n",
        "# %%\n",
        "@default_subscription\n",
        "class MessageRelayAgent(RoutedAgent):\n",
        "    \"\"\"\n",
        "    Agent that relays messages between different runtimes\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, name: str, target_worker=None):\n",
        "        super().__init__(f\"MessageRelay-{name}\")\n",
        "        self._name = name\n",
        "        self.target_worker = target_worker\n",
        "\n",
        "    def set_target_worker(self, worker):\n",
        "        \"\"\"Set the target worker for relaying messages\"\"\"\n",
        "        self.target_worker = worker\n",
        "\n",
        "    @message_handler\n",
        "    async def handle_message(self, message: TextMessage, ctx: MessageContext) -> None:\n",
        "        \"\"\"Relay messages to the target worker\"\"\"\n",
        "        if self.target_worker:\n",
        "            print(f\"\\nðŸ”„ Relay {self._name} forwarding message\")\n",
        "            await self.target_worker.publish_message(\n",
        "                message=message,\n",
        "                topic_id=DefaultTopicId()\n",
        "            )\n",
        "\n",
        "print(\"âœ… MessageRelayAgent implemented!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bgXzcSFL1iT",
        "outputId": "ce2c3c13-e9ea-4965-c19f-2af535ba0342"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Agent System manager created!\n"
          ]
        }
      ],
      "source": [
        "# ## 5. Simplified Agent System Manager\n",
        "# %%\n",
        "class AgentSystem:\n",
        "    \"\"\"\n",
        "    Simplified agent system with agents on different ports\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.host1 = None\n",
        "        self.host2 = None\n",
        "        self.worker1 = None\n",
        "        self.worker2 = None\n",
        "        self.is_running = False\n",
        "\n",
        "    async def start(self):\n",
        "        \"\"\"Start both agent hosts and workers\"\"\"\n",
        "        try:\n",
        "            print(\"ðŸš€ Starting Agent System...\")\n",
        "\n",
        "            # Start Host 1 (Port 50051)\n",
        "            self.host1 = GrpcWorkerAgentRuntimeHost(address=\"localhost:50051\")\n",
        "            self.host1.start()\n",
        "            print(\"âœ… Started Host 1 on localhost:50051\")\n",
        "\n",
        "            # Start Host 2 (Port 50052)\n",
        "            self.host2 = GrpcWorkerAgentRuntimeHost(address=\"localhost:50052\")\n",
        "            self.host2.start()\n",
        "            print(\"âœ… Started Host 2 on localhost:50052\")\n",
        "\n",
        "            # Small delay to ensure hosts are ready\n",
        "            await asyncio.sleep(1.0)\n",
        "\n",
        "            # Create Worker 1 connected to Host 1\n",
        "            self.worker1 = GrpcWorkerAgentRuntime(host_address=\"localhost:50051\")\n",
        "            await self.worker1.start()\n",
        "            print(\"âœ… Started Worker 1\")\n",
        "\n",
        "            # Create Worker 2 connected to Host 2\n",
        "            self.worker2 = GrpcWorkerAgentRuntime(host_address=\"localhost:50052\")\n",
        "            await self.worker2.start()\n",
        "            print(\"âœ… Started Worker 2\")\n",
        "\n",
        "            # Register BOTH agents on BOTH workers\n",
        "            # This enables cross-runtime communication\n",
        "\n",
        "            # Register on Worker 1\n",
        "            await RequestAgent.register(\n",
        "                self.worker1,\n",
        "                \"request_agent\",\n",
        "                lambda: RequestAgent(\"Agent1\")\n",
        "            )\n",
        "            await TranslatorAgent.register(\n",
        "                self.worker1,\n",
        "                \"translator_agent\",\n",
        "                lambda: TranslatorAgent(\"Agent2\")\n",
        "            )\n",
        "            print(\"âœ… Registered both agents on Worker 1\")\n",
        "\n",
        "            # Register on Worker 2\n",
        "            await RequestAgent.register(\n",
        "                self.worker2,\n",
        "                \"request_agent\",\n",
        "                lambda: RequestAgent(\"Agent1\")\n",
        "            )\n",
        "            await TranslatorAgent.register(\n",
        "                self.worker2,\n",
        "                \"translator_agent\",\n",
        "                lambda: TranslatorAgent(\"Agent2\")\n",
        "            )\n",
        "            print(\"âœ… Registered both agents on Worker 2\")\n",
        "\n",
        "            self.is_running = True\n",
        "            print(\"\\nðŸŽ‰ Agent System is running!\")\n",
        "            print(\"   - Host 1 on Port 50051\")\n",
        "            print(\"   - Host 2 on Port 50052\")\n",
        "            print(\"   - Both agents registered on both workers for cross-communication\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Failed to start agents: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            await self.stop()\n",
        "            raise\n",
        "\n",
        "    async def stop(self):\n",
        "        \"\"\"Stop all agents and hosts\"\"\"\n",
        "        print(\"\\nðŸ›‘ Stopping Agent System...\")\n",
        "        self.is_running = False\n",
        "\n",
        "        # Stop workers first\n",
        "        if self.worker1:\n",
        "            await self.worker1.stop()\n",
        "            print(\"âœ… Stopped Worker 1\")\n",
        "        if self.worker2:\n",
        "            await self.worker2.stop()\n",
        "            print(\"âœ… Stopped Worker 2\")\n",
        "\n",
        "        # Then stop hosts\n",
        "        if self.host1:\n",
        "            await self.host1.stop()\n",
        "            print(\"âœ… Stopped Host 1\")\n",
        "        if self.host2:\n",
        "            await self.host2.stop()\n",
        "            print(\"âœ… Stopped Host 2\")\n",
        "\n",
        "        print(\"âœ… All agents stopped\")\n",
        "\n",
        "    async def send_query(self, natural_language_query: str, schema: Dict) -> None:\n",
        "        \"\"\"Send a query translation request\"\"\"\n",
        "        if not self.is_running:\n",
        "            raise RuntimeError(\"Agent system is not running\")\n",
        "\n",
        "        # Create the request data\n",
        "        request_data = {\n",
        "            \"type\": \"QueryTranslationRequest\",\n",
        "            \"request_id\": f\"req_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}\",\n",
        "            \"natural_language_query\": natural_language_query,\n",
        "            \"database_schema\": schema,\n",
        "            \"sender\": \"system\",\n",
        "            \"timestamp\": datetime.now().isoformat()\n",
        "        }\n",
        "\n",
        "        # Create TextMessage with JSON content\n",
        "        message = TextMessage(\n",
        "            content=json.dumps(request_data),\n",
        "            source=\"system\"\n",
        "        )\n",
        "\n",
        "        # Log the request\n",
        "        log_communication(\"request\", \"system\", {\n",
        "            \"request_id\": request_data[\"request_id\"],\n",
        "            \"query\": natural_language_query,\n",
        "            \"schema\": schema\n",
        "        })\n",
        "\n",
        "        print(f\"\\nðŸ“¤ System sending query\")\n",
        "\n",
        "        # Send message through both workers to ensure delivery\n",
        "        await self.worker1.publish_message(\n",
        "            message=message,\n",
        "            topic_id=DefaultTopicId()\n",
        "        )\n",
        "        await self.worker2.publish_message(\n",
        "            message=message,\n",
        "            topic_id=DefaultTopicId()\n",
        "        )\n",
        "\n",
        "# Create global agent system instance\n",
        "agent_system = AgentSystem()\n",
        "print(\"âœ… Agent System manager created!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "A8OAjzRpoJib"
      },
      "outputs": [],
      "source": [
        "# ## 6. Test Function\n",
        "async def test_system():\n",
        "    \"\"\"Test the agent communication system\"\"\"\n",
        "    sample_schema = {\n",
        "        \"customers\": {\n",
        "            \"id\": \"integer\",\n",
        "            \"name\": \"varchar(100)\",\n",
        "            \"email\": \"varchar(100)\"\n",
        "        },\n",
        "        \"orders\": {\n",
        "            \"id\": \"integer\",\n",
        "            \"customer_id\": \"integer\",\n",
        "            \"amount\": \"decimal(10,2)\"\n",
        "        }\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        await agent_system.start()\n",
        "        await asyncio.sleep(1)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"ðŸ§ª TESTING AGENT COMMUNICATION\")\n",
        "        print(\"=\"*50)\n",
        "\n",
        "        # Send test query\n",
        "        await agent_system.send_query(\"Show customers with their order counts\", sample_schema)\n",
        "        await asyncio.sleep(3)  # Wait for response\n",
        "\n",
        "        print(\"\\nâœ… Test completed!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "    finally:\n",
        "        await agent_system.stop()\n",
        "\n",
        "# Run: await test_system()\n",
        "\n",
        "# ## Quick Test Function\n",
        "async def quick_api_test():\n",
        "    \"\"\"Quick test to verify API key is working\"\"\"\n",
        "    print(\"\\n=== Quick API Test ===\")\n",
        "\n",
        "    # Create a test translator\n",
        "    test_translator = TranslatorAgent(\"TestAgent\")\n",
        "\n",
        "    # Try to generate SQL\n",
        "    sql, conf, exp = await test_translator._generate_sql_with_llm(\n",
        "        \"Show all customers\",\n",
        "        {\"customers\": {\"id\": \"int\", \"name\": \"varchar\"}}\n",
        "    )\n",
        "\n",
        "    print(f\"\\nGenerated SQL: {sql}\")\n",
        "    print(f\"Confidence: {conf}\")\n",
        "    print(f\"Explanation: {exp}\")\n",
        "\n",
        "# Run this to test: await quick_api_test()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdQfR1l_OM_2",
        "outputId": "a92e3b58-18cb-4e84-a73d-ffb9149a08b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ðŸ“Š Table: customers\n",
            "   - id: INTEGER PRIMARY KEY\n",
            "   - name: VARCHAR(255)\n",
            "   - email: VARCHAR(255)\n",
            "   - created_at: TIMESTAMP\n",
            "   - city: VARCHAR(100)\n",
            "   - country: VARCHAR(100)\n",
            "\n",
            "ðŸ“Š Table: orders\n",
            "   - id: INTEGER PRIMARY KEY\n",
            "   - customer_id: INTEGER REFERENCES customers(id)\n",
            "   - amount: DECIMAL(10,2)\n",
            "   - order_date: TIMESTAMP\n",
            "   - status: VARCHAR(50)\n",
            "   - payment_method: VARCHAR(50)\n",
            "\n",
            "ðŸ“Š Table: products\n",
            "   - id: INTEGER PRIMARY KEY\n",
            "   - name: VARCHAR(255)\n",
            "   - category: VARCHAR(100)\n",
            "   - price: DECIMAL(10,2)\n",
            "   - stock: INTEGER\n",
            "   - description: TEXT\n",
            "\n",
            "ðŸ“Š Table: order_items\n",
            "   - id: INTEGER PRIMARY KEY\n",
            "   - order_id: INTEGER REFERENCES orders(id)\n",
            "   - product_id: INTEGER REFERENCES products(id)\n",
            "   - quantity: INTEGER\n",
            "   - unit_price: DECIMAL(10,2)\n"
          ]
        }
      ],
      "source": [
        "# ## 6. Sample Database Schema <a id=\"schema\"></a>\n",
        "#\n",
        "# Let's define a sample e-commerce database schema for testing.\n",
        "\n",
        "# %%\n",
        "# Sample database schema\n",
        "SAMPLE_SCHEMA = {\n",
        "    \"customers\": [\n",
        "        {\"name\": \"id\", \"type\": \"INTEGER PRIMARY KEY\"},\n",
        "        {\"name\": \"name\", \"type\": \"VARCHAR(255)\"},\n",
        "        {\"name\": \"email\", \"type\": \"VARCHAR(255)\"},\n",
        "        {\"name\": \"created_at\", \"type\": \"TIMESTAMP\"},\n",
        "        {\"name\": \"city\", \"type\": \"VARCHAR(100)\"},\n",
        "        {\"name\": \"country\", \"type\": \"VARCHAR(100)\"}\n",
        "    ],\n",
        "    \"orders\": [\n",
        "        {\"name\": \"id\", \"type\": \"INTEGER PRIMARY KEY\"},\n",
        "        {\"name\": \"customer_id\", \"type\": \"INTEGER REFERENCES customers(id)\"},\n",
        "        {\"name\": \"amount\", \"type\": \"DECIMAL(10,2)\"},\n",
        "        {\"name\": \"order_date\", \"type\": \"TIMESTAMP\"},\n",
        "        {\"name\": \"status\", \"type\": \"VARCHAR(50)\"},\n",
        "        {\"name\": \"payment_method\", \"type\": \"VARCHAR(50)\"}\n",
        "    ],\n",
        "    \"products\": [\n",
        "        {\"name\": \"id\", \"type\": \"INTEGER PRIMARY KEY\"},\n",
        "        {\"name\": \"name\", \"type\": \"VARCHAR(255)\"},\n",
        "        {\"name\": \"category\", \"type\": \"VARCHAR(100)\"},\n",
        "        {\"name\": \"price\", \"type\": \"DECIMAL(10,2)\"},\n",
        "        {\"name\": \"stock\", \"type\": \"INTEGER\"},\n",
        "        {\"name\": \"description\", \"type\": \"TEXT\"}\n",
        "    ],\n",
        "    \"order_items\": [\n",
        "        {\"name\": \"id\", \"type\": \"INTEGER PRIMARY KEY\"},\n",
        "        {\"name\": \"order_id\", \"type\": \"INTEGER REFERENCES orders(id)\"},\n",
        "        {\"name\": \"product_id\", \"type\": \"INTEGER REFERENCES products(id)\"},\n",
        "        {\"name\": \"quantity\", \"type\": \"INTEGER\"},\n",
        "        {\"name\": \"unit_price\", \"type\": \"DECIMAL(10,2)\"}\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Display schema nicely\n",
        "def display_schema(schema):\n",
        "    \"\"\"Display database schema in a readable format\"\"\"\n",
        "    for table_name, columns in schema.items():\n",
        "        print(f\"\\nðŸ“Š Table: {table_name}\")\n",
        "        for col in columns:\n",
        "            print(f\"   - {col['name']}: {col['type']}\")\n",
        "\n",
        "display_schema(SAMPLE_SCHEMA)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXEUQxqDOWAm",
        "outputId": "9c6015c1-5174-40da-a9d5-78ea016b5279"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Gradio helper functions ready!\n"
          ]
        }
      ],
      "source": [
        "# ## 7. Gradio Interface Implementation <a id=\"interface\"></a>\n",
        "#\n",
        "# Now let's create an interactive Gradio interface for our system.\n",
        "\n",
        "# %%\n",
        "# Helper functions for Gradio interface\n",
        "\n",
        "async def start_agents_handler():\n",
        "    \"\"\"Start the agent system\"\"\"\n",
        "    try:\n",
        "        clear_communication_log()\n",
        "        await agent_system.start()\n",
        "        return \"âœ… Agent system started successfully!\", get_communication_log_html()\n",
        "    except Exception as e:\n",
        "        return f\"âŒ Failed to start: {str(e)}\", get_communication_log_html()\n",
        "\n",
        "async def stop_agents_handler():\n",
        "    \"\"\"Stop the agent system\"\"\"\n",
        "    try:\n",
        "        await agent_system.stop()\n",
        "        return \"â¹ï¸ Agent system stopped\", get_communication_log_html()\n",
        "    except Exception as e:\n",
        "        return f\"âŒ Failed to stop: {str(e)}\", get_communication_log_html()\n",
        "\n",
        "async def send_query_handler(query, custom_schema):\n",
        "    \"\"\"Send a translation request\"\"\"\n",
        "    if not agent_system.is_running:\n",
        "        return \"âŒ Agent system is not running. Please start it first.\", get_communication_log_html()\n",
        "\n",
        "    # Parse custom schema if provided\n",
        "    schema = SAMPLE_SCHEMA\n",
        "    if custom_schema and custom_schema.strip():\n",
        "        try:\n",
        "            schema = json.loads(custom_schema)\n",
        "        except json.JSONDecodeError:\n",
        "            return \"âŒ Invalid schema JSON format\", get_communication_log_html()\n",
        "\n",
        "    try:\n",
        "        await agent_system.send_query(query, schema)\n",
        "        # Wait for response\n",
        "        await asyncio.sleep(2.5)\n",
        "        return f\"âœ… Query sent: {query}\", get_communication_log_html()\n",
        "    except Exception as e:\n",
        "        return f\"âŒ Error: {str(e)}\", get_communication_log_html()\n",
        "\n",
        "def get_communication_log_html():\n",
        "    \"\"\"Format communication log as HTML for display\"\"\"\n",
        "    html = \"<div style='font-family: monospace; font-size: 12px;'>\"\n",
        "\n",
        "    # Show last 20 entries\n",
        "    for entry in communication_log[-20:]:\n",
        "        timestamp = entry['timestamp'].split('T')[1].split('.')[0]\n",
        "\n",
        "        if entry['type'] == 'request':\n",
        "            html += f\"\"\"\n",
        "            <div style='background: #e3f2fd; padding: 10px; margin: 5px; border-radius: 5px; border-left: 4px solid #2196F3;'>\n",
        "                <strong>ðŸ“¤ REQUEST</strong> from {entry['agent']} at {timestamp}<br>\n",
        "                <strong>Query:</strong> \"{entry['data']['query']}\"<br>\n",
        "                <strong>Request ID:</strong> {entry['data']['request_id']}<br>\n",
        "                <strong>Tables:</strong> {', '.join(entry['data']['schema'].keys())}\n",
        "            </div>\n",
        "            \"\"\"\n",
        "        elif entry['type'] == 'processing':\n",
        "            html += f\"\"\"\n",
        "            <div style='background: #fff3e0; padding: 10px; margin: 5px; border-radius: 5px; border-left: 4px solid #FF9800;'>\n",
        "                <strong>âš™ï¸ PROCESSING</strong> by {entry['agent']} at {timestamp}<br>\n",
        "                {entry['data']['status']}\n",
        "            </div>\n",
        "            \"\"\"\n",
        "        elif entry['type'] == 'response':\n",
        "            html += f\"\"\"\n",
        "            <div style='background: #e8f5e9; padding: 10px; margin: 5px; border-radius: 5px; border-left: 4px solid #4CAF50;'>\n",
        "                <strong>ðŸ“¥ RESPONSE</strong> to {entry['agent']} at {timestamp}<br>\n",
        "                <strong>SQL Query:</strong><br>\n",
        "                <pre style='background: #f5f5f5; padding: 8px; margin: 5px 0; border-radius: 3px; overflow-x: auto;'>{entry['data']['sql_query']}</pre>\n",
        "                <strong>Confidence:</strong> {entry['data']['confidence']:.1%}<br>\n",
        "                <strong>Explanation:</strong> {entry['data']['explanation']}\n",
        "            </div>\n",
        "            \"\"\"\n",
        "\n",
        "    if not communication_log:\n",
        "        html += \"<p style='color: #666;'>No communication yet...</p>\"\n",
        "\n",
        "    html += \"</div>\"\n",
        "    return html\n",
        "\n",
        "print(\"âœ… Gradio helper functions ready!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pP0R-s8oOaSH",
        "outputId": "92e16179-7686-47fb-b94a-fd35b3a5029d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Gradio interface created!\n"
          ]
        }
      ],
      "source": [
        "# ## 8. Create and Launch Gradio Interface <a id=\"gradio\"></a>\n",
        "\n",
        "# %%\n",
        "# Create Gradio interface\n",
        "def create_gradio_interface():\n",
        "    \"\"\"Create the Gradio web interface\"\"\"\n",
        "\n",
        "    with gr.Blocks(title=\"AutoGen SQL Translation System\", theme=gr.themes.Soft()) as demo:\n",
        "        gr.Markdown(\"\"\"\n",
        "        # ðŸš€ AutoGen SQL Translation System with gRPC Communication\n",
        "\n",
        "        This demo showcases a distributed AI agent system using Microsoft's AutoGen framework:\n",
        "\n",
        "        - **Agent 1** (Port 50051): Sends natural language queries for SQL translation\n",
        "        - **Agent 2** (Port 50052): Uses LLM-like logic to translate queries to SQL\n",
        "        - **Communication**: Agents communicate via gRPC protocol\n",
        "\n",
        "        ---\n",
        "        \"\"\")\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=1):\n",
        "                gr.Markdown(\"### ðŸŽ›ï¸ System Control\")\n",
        "\n",
        "                with gr.Row():\n",
        "                    start_btn = gr.Button(\"ðŸš€ Start Agents\", variant=\"primary\", scale=1)\n",
        "                    stop_btn = gr.Button(\"â¹ï¸ Stop Agents\", variant=\"stop\", scale=1)\n",
        "\n",
        "                status = gr.Textbox(\n",
        "                    label=\"System Status\",\n",
        "                    value=\"System not started\",\n",
        "                    lines=1\n",
        "                )\n",
        "\n",
        "                gr.Markdown(\"### ðŸ“ Query Translation\")\n",
        "\n",
        "                query_input = gr.Textbox(\n",
        "                    label=\"Natural Language Query\",\n",
        "                    placeholder=\"e.g., Show me all customers who have placed orders\",\n",
        "                    lines=3\n",
        "                )\n",
        "\n",
        "                # Example queries\n",
        "                gr.Examples(\n",
        "                    examples=[\n",
        "                        \"Show me all customers\",\n",
        "                        \"Count total orders\",\n",
        "                        \"Get total order amount\",\n",
        "                        \"Show customers with their order counts\",\n",
        "                        \"List top customers by spending\",\n",
        "                        \"Show recent orders\",\n",
        "                        \"Find customers with email addresses\",\n",
        "                        \"Show all products with low stock\"\n",
        "                    ],\n",
        "                    inputs=query_input,\n",
        "                    label=\"Example Queries\"\n",
        "                )\n",
        "\n",
        "                with gr.Accordion(\"Advanced Options\", open=False):\n",
        "                    schema_input = gr.Code(\n",
        "                        label=\"Custom Schema (JSON)\",\n",
        "                        language=\"json\",\n",
        "                        value=\"\",\n",
        "                        lines=10\n",
        "                    )\n",
        "\n",
        "                    gr.Markdown(\"\"\"\n",
        "                    **Note:** Leave empty to use the default e-commerce schema.\n",
        "\n",
        "                    Example custom schema:\n",
        "                    ```json\n",
        "                    {\n",
        "                        \"users\": [\n",
        "                            {\"name\": \"id\", \"type\": \"INTEGER\"},\n",
        "                            {\"name\": \"username\", \"type\": \"VARCHAR(50)\"}\n",
        "                        ]\n",
        "                    }\n",
        "                    ```\n",
        "                    \"\"\")\n",
        "\n",
        "                send_btn = gr.Button(\"ðŸ“¤ Send Query\", variant=\"primary\", size=\"lg\")\n",
        "\n",
        "            with gr.Column(scale=2):\n",
        "                gr.Markdown(\"### ðŸ“¡ Agent Communication Log\")\n",
        "\n",
        "                comm_log = gr.HTML(\n",
        "                    label=\"Communication Log\",\n",
        "                    value=get_communication_log_html()\n",
        "                )\n",
        "\n",
        "                with gr.Row():\n",
        "                    refresh_btn = gr.Button(\"ðŸ”„ Refresh Log\", scale=1)\n",
        "                    clear_btn = gr.Button(\"ðŸ—‘ï¸ Clear Log\", scale=1)\n",
        "\n",
        "                gr.Markdown(\"\"\"\n",
        "                **Legend:**\n",
        "                - ðŸ“¤ Blue: Request sent by Agent 1\n",
        "                - âš™ï¸ Orange: Processing by Agent 2\n",
        "                - ðŸ“¥ Green: Response received by Agent 1\n",
        "                \"\"\")\n",
        "\n",
        "        # Event handlers\n",
        "        start_btn.click(\n",
        "            fn=start_agents_handler,\n",
        "            outputs=[status, comm_log]\n",
        "        )\n",
        "\n",
        "        stop_btn.click(\n",
        "            fn=stop_agents_handler,\n",
        "            outputs=[status, comm_log]\n",
        "        )\n",
        "\n",
        "        send_btn.click(\n",
        "            fn=send_query_handler,\n",
        "            inputs=[query_input, schema_input],\n",
        "            outputs=[status, comm_log]\n",
        "        )\n",
        "\n",
        "        refresh_btn.click(\n",
        "            fn=lambda: (\"Current status\", get_communication_log_html()),\n",
        "            outputs=[status, comm_log]\n",
        "        )\n",
        "\n",
        "        clear_btn.click(\n",
        "            fn=lambda: (clear_communication_log(), \"Log cleared\", get_communication_log_html()),\n",
        "            outputs=[status, comm_log]\n",
        "        )\n",
        "\n",
        "    return demo\n",
        "\n",
        "# Create the interface\n",
        "demo = create_gradio_interface()\n",
        "print(\"âœ… Gradio interface created!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HK5GIhblOfic",
        "outputId": "151575a6-b918-4f70-93cb-870acec12df5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸš€ Launching Gradio interface...\n",
            "Please wait for the public URL to appear below...\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://a18be52e7bd0c7c0ed.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://a18be52e7bd0c7c0ed.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Communication log cleared\n",
            "ðŸš€ Starting Agent System...\n",
            "âœ… Started Host 1 on localhost:50051\n",
            "âœ… Started Host 2 on localhost:50052\n",
            "âœ… Started Worker 1\n",
            "âœ… Started Worker 2\n",
            "âœ… Registered both agents on Worker 1\n",
            "âœ… Registered both agents on Worker 2\n",
            "\n",
            "ðŸŽ‰ Agent System is running!\n",
            "   - Host 1 on Port 50051\n",
            "   - Host 2 on Port 50052\n",
            "   - Both agents registered on both workers for cross-communication\n",
            "[REQUEST] system: Show me all customers\n",
            "\n",
            "ðŸ“¤ System sending query\n",
            "   âœ… Gemini LLM client initialized for Agent2\n",
            "\n",
            "ðŸ“¥ TranslatorAgent received request from: system\n",
            "   Message type: QueryTranslationRequest\n",
            "   Processing translation request: req_20250726_225019_020876\n",
            "[PROCESSING] Agent2: Translating query...\n",
            "   ðŸ¤– Calling Gemini LLM...\n",
            "   âœ… Gemini LLM client initialized for Agent2\n",
            "\n",
            "ðŸ“¥ TranslatorAgent received request from: system\n",
            "   Message type: QueryTranslationRequest\n",
            "   Processing translation request: req_20250726_225019_020876\n",
            "[PROCESSING] Agent2: Translating query...\n",
            "   ðŸ¤– Calling Gemini LLM...\n",
            "id='a70b41f9-c25d-43f6-9e3b-a01b4be3d476' source='Agent2' models_usage=RequestUsage(prompt_tokens=438, completion_tokens=56) metadata={} created_at=datetime.datetime(2025, 7, 26, 22, 50, 20, 614324, tzinfo=datetime.timezone.utc) content='```json\\n{\\n  \"sql_query\": \"SELECT * FROM customers;\",\\n  \"confidence\": 1.0,\\n  \"explanation\": \"This query selects all columns and rows from the \\'customers\\' table, effectively showing all customers.\"\\n}\\n```' type='TextMessage'\n",
            "{'sql_query': 'SELECT * FROM customers;', 'confidence': 1.0, 'explanation': \"This query selects all columns and rows from the 'customers' table, effectively showing all customers.\"}\n",
            "   âœ… LLM generated SQL successfully\n",
            "   ðŸ“¤ Sending response back\n",
            "id='e33b5a4c-b2e8-458b-a0e7-3dd3f492d5c6' source='Agent2' models_usage=RequestUsage(prompt_tokens=438, completion_tokens=57) metadata={} created_at=datetime.datetime(2025, 7, 26, 22, 50, 20, 617401, tzinfo=datetime.timezone.utc) content='```json\\n{\\n  \"sql_query\": \"SELECT * FROM customers;\",\\n  \"confidence\": 1.0,\\n  \"explanation\": \"This query selects all columns and rows from the \\'customers\\' table, effectively displaying all customer information.\"\\n}\\n```' type='TextMessage'\n",
            "{'sql_query': 'SELECT * FROM customers;', 'confidence': 1.0, 'explanation': \"This query selects all columns and rows from the 'customers' table, effectively displaying all customer information.\"}\n",
            "   âœ… LLM generated SQL successfully\n",
            "   ðŸ“¤ Sending response back\n",
            "\n",
            "ðŸ“¥ RequestAgent received response from: Agent2\n",
            "   Message type: QueryTranslationResponse\n",
            "\n",
            "ðŸ“¥ RequestAgent received response from: Agent2\n",
            "   Message type: QueryTranslationResponse\n"
          ]
        }
      ],
      "source": [
        "# ## 9. Launch the Application <a id=\"launch\"></a>\n",
        "#\n",
        "# Now let's launch the Gradio interface. In Google Colab, this will create a public URL.\n",
        "\n",
        "# %%\n",
        "# Launch the Gradio interface\n",
        "print(\"ðŸš€ Launching Gradio interface...\")\n",
        "print(\"Please wait for the public URL to appear below...\\n\")\n",
        "\n",
        "# Launch with public link for Colab\n",
        "demo.queue().launch(share=True, debug=True)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
